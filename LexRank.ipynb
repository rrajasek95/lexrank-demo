{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of tf-idf\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRESIDENT HARRY S. TRUMAN'S ADDRESS BEFORE A JOINT SESSION OF THE CONGRESS\n",
      " \n",
      "April 16, 1945\n",
      "\n",
      "Mr. Speaker, Mr. President, Members of the Congress:\n",
      "It is with a heavy heart that I stand before you, my f\n"
     ]
    }
   ],
   "source": [
    "file_id = nltk.corpus.state_union.fileids()[0]\n",
    "text = nltk.corpus.state_union.raw(file_id)\n",
    "\n",
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.466337068793427\n"
     ]
    }
   ],
   "source": [
    "from idf import computeWordIdf\n",
    "from util import preprocess_sotu_text\n",
    "\n",
    "documents = map(nltk.corpus.state_union.raw, nltk.corpus.state_union.fileids())\n",
    "processed_documents = map(preprocess_sotu_text, documents)\n",
    "word_idf = computeWordIdf(processed_documents)\n",
    "print(word_idf['harry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As I have assumed my heavy duties, I humbly pray Almighty God, in the words of King Solomon:\n",
      "\"Give therefore thy servant an understanding heart to judge thy people, that I may discern between good and bad; for who is able to judge this thy so great a people?\"\n",
      "We are now carrying out our part of that strategy under the able direction of Admiral Leahy, General Marshall, A dmiral King, General Arnold, General Eisenhower, Admiral Nimitz and General MacArthur.\n",
      "We shall need also an abiding faith in the people, the kind of faith and courage which Franklin Delano Roosevelt always had!\n",
      "So much blood has already been shed for the ideals which we cherish, and for which Franklin Delano Roosevelt lived and died, that we dare not permit even a momentary pause in the hard fight for victory.\n",
      "In the memory of those who have made the supreme sacrifice-in the memory of our fallen President-we shall not fail!\n",
      "Having to pay such a heavy price to make complete victory certain, America will never become a party to any plan for partial victory!\n",
      "So that there can be no possible misunderstanding, both Germany and Japan can be certain, beyond any shadow of a doubt, that America will continue the fight for freedom until no vestige of resistance remains!\n",
      "On the battlefields, we have frequently faced overwhelming odds - and won!\n",
      "In the name of human decency and civilization, a more rational method of deciding national differences must and will be found!\n",
      "I want the entire world to know that this direction must and will remain-unchanged and unhampered!\n",
      "During the dark hours of this horrible war, entire nations were kept going by something intangible-hope!\n",
      "We well know today that such rights can be preserved only by constant vigilance , the eternal price of liberty!\n",
      "Only yesterday, we laid to rest the mortal remains of our beloved President, Franklin Delano Roosevelt.\n",
      "Our demand has been, and it remains-Unconditional Surrender!\n",
      "Hope has become the secret weapon of the forces of liberation!\n",
      "At home, Americans will not be less resolute!\n",
      "With tragic fatalism, they insist that wars have always been, of necessity, and of necessity wars always will be.\n",
      "With great humility I call upon all Americans to help me keep our nation united in defense of those ideals which have been so eloquently proclaimed by Franklin Roosevelt.\n",
      "Because of these sacrifices, the dawn of justice and freedom throughout th e world slowly casts its gleam across the horizon.\n",
      "Lasting peace can never be secured if we permit our dangerous opponents to plot future wars with impunity at any mountain retreat - however distant.\n"
     ]
    }
   ],
   "source": [
    "from centroid import CentroidScorer\n",
    "\n",
    "documents = map(nltk.corpus.state_union.raw, nltk.corpus.state_union.fileids())\n",
    "processed_documents = map(preprocess_sotu_text, documents)\n",
    "\n",
    "scorer = CentroidScorer(1.5)\n",
    "scorer.fit(processed_documents)\n",
    "\n",
    "test_fileid = nltk.corpus.state_union.fileids()[0]\n",
    "test_text = nltk.corpus.state_union.raw(test_fileid)\n",
    "processed_text = preprocess_sotu_text(test_text)\n",
    "\n",
    "sentence_with_scores = scorer.score(processed_text)\n",
    "\n",
    "from operator import itemgetter\n",
    "sorted_sentence_with_scores = sorted(sentence_with_scores, key=itemgetter('score'), reverse=True)\n",
    "for sentence_with_score in sorted_sentence_with_scores[:20]:\n",
    "    print(sentence_with_score['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the idf-modified cosine\n",
    "\n",
    "import nltk.data\n",
    "from nltk.tokenize.nist import NISTTokenizer\n",
    "from idf import tfIdf\n",
    "\n",
    "punkt_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "test_fileid = nltk.corpus.state_union.fileids()[0]\n",
    "test_text = nltk.corpus.state_union.raw(test_fileid)\n",
    "processed_text = preprocess_sotu_text(test_text)\n",
    "\n",
    "sentences = punkt_tokenizer.tokenize(processed_text)\n",
    "nist = NISTTokenizer()\n",
    "sentence1_tfidf = tfIdf(word_idf, nist.tokenize(sentences[0], lowercase=True))\n",
    "sentence2_tfidf = tfIdf(word_idf, nist.tokenize(sentences[1], lowercase=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {'president': 0.0, 'harry': 1.466337068793427, 's': 1.0833448165373212, '.': 0.0, \"truman's\": 2.094945728215801, 'address': 0.39019763597737595, 'before': 0.06250508700820906, 'a': 0.0, 'joint': 0.30318625898774626, 'session': 0.18540322333136275, 'of': 0.0, 'the': 0.0, 'congress': 0.0, 'april': 1.6094379124341003, '16': 1.341173925839421, ',': 0.0, '1945': 2.228477120840324, 'mr': 0.3708064466627255, 'speaker': 0.20409535634351522, 'members': 0.03125254350410453, ':': 0.0, 'it': 0.0, 'is': 0.0, 'with': 0.0, 'heavy': 1.1786549963416462, 'heart': 0.6480267452794758, 'that': 0.0, 'i': 0.0, 'stand': 0.28256697178501045, 'you': 0.06351340572232593, 'my': 0.015504186535965254, 'friends': 0.22314355131420976, 'and': 0.0, 'colleagues': 1.9771626925594177, 'in': 0.0, 'united': 0.03125254350410453, 'states': 0.0})\n",
      "defaultdict(<class 'float'>, {'only': 0.015504186535965254, 'yesterday': 1.8718021769015913, ',': 0.0, 'we': 0.0, 'laid': 1.1298648321722142, 'to': 0.0, 'rest': 0.5634693572514127, 'the': 0.0, 'mortal': 3.481240089335692, 'remains': 0.6778797084291569, 'of': 0.0, 'our': 0.0, 'beloved': 1.9771626925594177, 'president': 0.0, 'franklin': 1.6094379124341003, 'delano': 3.0757749812275277, 'roosevelt': 1.2299482907291965, '.': 0.0})\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(sentence1_tfidf)\n",
    "print(sentence2_tfidf)\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "def norm(vals):\n",
    "    return sqrt(sum([x*x for x in vals]))\n",
    "\n",
    "def idfCosine(sent1_tfidf, sent2_tfidf):\n",
    "    sent1_norm = norm(sent1_tfidf.values())\n",
    "    sent2_norm = norm(sent2_tfidf.values())\n",
    "    if sent1_norm == 0. or sent2_norm == 0.:\n",
    "        return 0.\n",
    "    inner_product = sum(sent1_tfidf[word]*sent2_tfidf.get(word, 0.) for word in sent1_tfidf.keys())\n",
    "    cosine = inner_product/(sent1_norm*sent2_norm)\n",
    "    \n",
    "    return cosine\n",
    "\n",
    "print(idfCosine(sentence1_tfidf, sentence2_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tfidfs = [tfIdf(word_idf, nist.tokenize(sentence, lowercase=True)) for sentence in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 0.00000000e+00 0.00000000e+00 ... 4.62121200e-02\n",
      "  2.98009651e-02 2.17263792e-05]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 8.86043468e-06]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 ... 0.00000000e+00\n",
      "  1.90661970e-02 0.00000000e+00]\n",
      " ...\n",
      " [4.62121200e-02 0.00000000e+00 0.00000000e+00 ... 1.00000000e+00\n",
      "  1.77975527e-02 5.58752022e-05]\n",
      " [2.98009651e-02 0.00000000e+00 1.90661970e-02 ... 1.77975527e-02\n",
      "  1.00000000e+00 7.63977721e-02]\n",
      " [2.17263792e-05 8.86043468e-06 0.00000000e+00 ... 5.58752022e-05\n",
      "  7.63977721e-02 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "similarity_matrix = np.matrix([[idfCosine(s1, s2) for s2 in sentence_tfidfs] for s1 in sentence_tfidfs])\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At home, Americans will not be less resolute!\n",
      "Hope has become the secret weapon of the forces of liberation!\n",
      "We shall need also an abiding faith in the people, the kind of faith and courage which Franklin Delano Roosevelt always had!\n",
      "Having to pay such a heavy price to make complete victory certain, America will never become a party to any plan for partial victory!\n",
      "We well know today that such rights can be preserved only by constant vigilance , the eternal price of liberty!\n",
      "Hope was not enough to beat back the aggressors as long as the peace-loving nations were unwilling to come to each other's defense.\n",
      "The aggressors were beaten back only when the peace-loving nations united to defend themselves.\n",
      "Only yesterday, we laid to rest the mortal remains of our beloved President, Franklin Delano Roosevelt.\n",
      "We must carry on.Our departed leader never looked backward.\n",
      "So much blood has already been shed for the ideals which we cherish, and for which Franklin Delano Roosevelt lived and died, that we dare not permit even a momentary pause in the hard fight for victory.\n",
      "Such a leadership requires vision, courage and tolerance.\n",
      "Our demand has been, and it remains-Unconditional Surrender!\n",
      "I want the entire world to know that this direction must and will remain-unchanged and unhampered!\n",
      "Our forefathers came to our rugged shores in search of religious tolerance, political freedom and economic opportunity.\n",
      "During the dark hours of this horrible war, entire nations were kept going by something intangible-hope!\n",
      "Aggressors could not dominate the human mind.\n",
      "We must not only have hope but we must have faith enough to work with other peace-loving nations to maintain the peace.\n",
      "In the name of human decency and civilization, a more rational method of deciding national differences must and will be found!\n",
      "This will require time and tolerance.\n",
      "The most eloquent tribute would be a reverent silence.\n"
     ]
    }
   ],
   "source": [
    "cosine_threshold = 0.2\n",
    "\n",
    "# Find all elements where similarity exceeds threshold (excluding the self links)\n",
    "cross_connectivity_matrix = (similarity_matrix > cosine_threshold) - np.identity(len(sentences))\n",
    "sentence_degrees = np.sum(cross_connectivity_matrix, axis=0).T\n",
    "sentence_degrees_list = sentence_degrees.tolist()\n",
    "sentences_with_score = [(sentences[i], sentence_degrees_list[i]) for i in range(len(sentences))]\n",
    "sorted_sentences_with_score = sorted(sentences_with_score, key=itemgetter(1), reverse=True)\n",
    "\n",
    "for sentence_with_score in sorted_sentences_with_score[:20]:\n",
    "    print(sentence_with_score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lex Rank logic\n",
    "cosine_thresholded_similarities = (similarity_matrix > cosine_threshold)\n",
    "cosine_degrees = np.sum(cosine_thresholded_similarities, axis=0)\n",
    "degree_averaged_cosine_matrix = cosine_thresholded_similarities/cosine_degrees.T\n",
    "\n",
    "def powerMethod(matrix, tolerance):\n",
    "    damping_factor= 0.15\n",
    "    N = matrix.shape[0]\n",
    "    p = np.ones((N, 1))\n",
    "    \n",
    "    U_kernel = np.ones(matrix.shape)/N\n",
    "    B_kernel = matrix\n",
    "    M = damping_factor * U_kernel + (1 - damping_factor)*B_kernel\n",
    "    \n",
    "    while True:\n",
    "        p_new = M.T * p\n",
    "        error = np.linalg.norm(p_new - p)\n",
    "        if error < tolerance:\n",
    "            break\n",
    "        p = p_new\n",
    "        \n",
    "    return p\n",
    "\n",
    "lexrank_array = powerMethod(degree_averaged_cosine_matrix, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At home, Americans will not be less resolute!\n",
      "Hope has become the secret weapon of the forces of liberation!\n",
      "We must carry on.Our departed leader never looked backward.\n",
      "We shall need also an abiding faith in the people, the kind of faith and courage which Franklin Delano Roosevelt always had!\n",
      "Hope was not enough to beat back the aggressors as long as the peace-loving nations were unwilling to come to each other's defense.\n",
      "The aggressors were beaten back only when the peace-loving nations united to defend themselves.\n",
      "As I have assumed my heavy duties, I humbly pray Almighty God, in the words of King Solomon:\n",
      "\"Give therefore thy servant an understanding heart to judge thy people, that I may discern between good and bad; for who is able to judge this thy so great a people?\"\n",
      "At this moment, I have in my heart a prayer.\n",
      "In that way, America may well lead the world to peace and prosperity.\n",
      "May we Americans all live up to our glorious heritage.\n",
      "We must learn to trade more with other nations so that there may be-for our mutual advantage-increased product ion, increased employment and better standards of living throughout the world.\n",
      "We must now learn to live with other nations for our mutual good.\n",
      "We have achieved a world leadership which does not depend solely upon our military and naval might.\n",
      "We must keep it so.\n",
      "Today, America has become one of the most powerful forces for good on earth.\n",
      "Only with your help can I hope to complete one of the greatest tasks ever assigned to a public servant.\n",
      "To destroy greedy tyrants with dreams of world domination, we cannot continue in successive generations to sacrifice our finest youth.\n",
      "I ask only to be a good and faithful servant of my Lord and my people.\n",
      "With confidence, I am depending upon all of you.\n",
      "With Divine guidance, and your help, we will find the new passage to a far better world, a kindly and friendly world, with just and lasting peace.\n"
     ]
    }
   ],
   "source": [
    "scores_array = lexrank_array.tolist()\n",
    "\n",
    "sentences_with_score = [(sentences[i], lexrank_array[i]) for i in range(len(sentences))]\n",
    "sorted_sentences_with_score = sorted(sentences_with_score, key=itemgetter(1), reverse=True)\n",
    "\n",
    "for sentence_with_score in sorted_sentences_with_score[:20]:\n",
    "    print(sentence_with_score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
